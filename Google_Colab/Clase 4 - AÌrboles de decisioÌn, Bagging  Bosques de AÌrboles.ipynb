{"cells":[{"cell_type":"markdown","metadata":{"id":"w1Lippf2K_td"},"source":["# Árboles de decisión\n","\n","En esta clase revisaremos el primer modelo de Machine Learning que veremos, llamado Árbol de decisión. Los Árboles son modelos bastante versátiles y potentes en el mundo del Machine Learning, los cuales presentan las siguientes características:\n","\n","- Se pueden utilizar para problemas de clasificación, regresión u otros\n","- No requiere escalar las variables de ingreso\n","- Alta interpretabilidad\n","- Forman la base de modelos más sofisticados (Random Forest, entre otros)\n"," \n","Para mostrar lo que podemos hacer con un árbol de decisión, utilizaremos un set de datos sobre los precios de inmuebles en la ciudad de Ames, Iowa. \n","La base se compone de 2930 registros y contiene un gran número de atributos. \n","Nuestro objetivo es generar un modelo que prediga de forma adecuada los precios de inmuebles, medidos con la variable Sale_Price (variable numérica)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":204,"status":"ok","timestamp":1629333926714,"user":{"displayName":"Bastian Ignacio Galasso Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtjU_q4of0391TspQQlOEne6JbWj-TLNVv9R63=s64","userId":"13315192994116652809"},"user_tz":240},"id":"W8Gb-0gyV0OH","vscode":{"languageId":"r"}},"outputs":[],"source":["require(tidyverse)\n","require(tidymodels)\n","require(Metrics)\n","require(rpart.plot)\n","require(rattle)\n","require(rpart)\n","require(baguette)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0wyCMc1EM74c","vscode":{"languageId":"r"}},"outputs":[],"source":["#Cargamos los datos\n","ames <- read.csv('~/diplomado_DS_2022/Data/ames_housing.csv')\n","ames <- ames\n","head(ames)"]},{"cell_type":"markdown","metadata":{},"source":["Lo primero es ver que tipo de datos son, antes de poder manipular los datos."]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["chr_cols <- ames %>%\n","   select_if(is.character)\n","chr_cols <- colnames(chr_cols)\n","ames <- ames %>%\n","   mutate_each_(funs(factor(.)),chr_cols)\n","glimpse(ames)"]},{"cell_type":"markdown","metadata":{},"source":["Además de lo anterior, la primera columna es un indicador, y además la latitud y longitud tipicamente no entregan información relevante tal y como están, por lo que las eliminaremos"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["ames <- ames %>%\n","  select(-X,-Longitude,-Latitude)\n","\n","#Revisando si hay NAs\n","apply(is.na(ames),2,sum)"]},{"cell_type":"markdown","metadata":{"id":"knp5fqOmahZL"},"source":["Luego sin más rodeos, ajustaremos nuestro modelo de árbol de decisión (en este caso, de regresión). Para ello debemos crear nuestro set de entrenamiento y testeo"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"elapsed":415,"status":"ok","timestamp":1629333932521,"user":{"displayName":"Bastian Ignacio Galasso Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtjU_q4of0391TspQQlOEne6JbWj-TLNVv9R63=s64","userId":"13315192994116652809"},"user_tz":240},"id":"QsLXw6ewarU2","outputId":"595071b7-187b-4acd-d160-f538e0973711","vscode":{"languageId":"r"}},"outputs":[],"source":["traintest_split <- initial_split(ames, prop = 0.8, strata = NULL)\n","train_set <- training(traintest_split)\n","test_set <- testing(traintest_split)\n","dim(train_set)\n","dim(test_set)"]},{"cell_type":"markdown","metadata":{},"source":["Para entrenar utilizaremos el workflow de trabajo de `tidymodels` que nos permite entrenar todo tipo de modelos, en particular árboles de decisión, entonces primero veremos un poco como se utiliza. En este caso usaremos la función `decision_tree`que nos permitirá ajustar un árbol de decisión, utilizando distintos motores existentes del modelo. "]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["tree_model <- decision_tree(\n","  mode = \"regression\", #Aquí podemos usar regression, classification o unknown\n","  engine = \"rpart\" #Existen distintos tipos de motores, ya lo veremos\n",")\n","tree_model"]},{"cell_type":"markdown","metadata":{},"source":["A un modelo podemos ir modificandolo después de creado sin problema, por ejemplo podemos cambiar el modo"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["tree_model <- tree_model %>%\n","    set_mode('classification')\n","translate(tree_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["tree_model"]},{"cell_type":"markdown","metadata":{},"source":["Ahora tenemos creado un modelo, que será de tipo regresión (variable target continua) y utilizará el motor de ajuste de rpart. Para revisar los distintos motores que se pueden utilizar se utiliza la función `show_engines`"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["show_engines('decision_tree')"]},{"cell_type":"markdown","metadata":{},"source":["Ahora, si nos damos cuenta en la parte anterior, hemos creado un modelo pero ¿le entregamos datos? No! en ningún lado le hemos entregado datos al modelo, por lo que si bien hemos creado el modelo, no lo hemos entrenado, que son dos cosas distintas: Primero seleccionamos el modelo a utilizar y luego lo entrenamos, que es lo que veremos ahora. Para entrenar, utilizaremos la funcion `fit`"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["tree_fit <- tree_model %>%\n","    set_mode('regression') %>%\n","    fit(Sale_Price ~ ., data = train_set)\n","tree_fit"]},{"cell_type":"markdown","metadata":{},"source":["Lo anterior uno puede entenderlo pero no se ve una ganancia en utilizar esta forma de hacer el modelo, más allá del cambio de motor que utiliza el ajuste. Entonces ahora si, veremos algo que genera un ajuste de modelo basado en recetas, mediante la función `recipe` "]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["tree_rec <- recipe(Sale_Price ~ ., data = train_set)"]},{"cell_type":"markdown","metadata":{},"source":["¿Por qué esto es útil? básicamente porque nos permite ajustar distintos modelos (cambiando variables por ejemplo) y/o cambiar el motor utilizado, sin tener que practicamente hacer copy & paste de un codigo e ir modificando. Por otro lado, este tipo de funciones permiten adaptar los roles de las variables (¿roles?). Esto es, cuando ponemos `Sales_price ~ .` significa que Sales_price es el outcome o target, y las demás predictores. Pero si tenemos variables tipo ID? Las podemos eliminar, pero puede ser de utilidad dejarlas para después analizar los resultados."]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["tree_rec <- recipe(Sale_Price ~ ., data = train_set) %>%\n","    update_role(Alley, new_role = 'ID')\n","summary(tree_rec)"]},{"cell_type":"markdown","metadata":{},"source":["Finalmente, creamos el workflow que nos permite tomar todos los ingredientes anteriores y poder ajustar el modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["tree_workflow <- workflow() %>%\n","    add_model(tree_model) %>%\n","    add_recipe(tree_rec)\n","tree_workflow"]},{"cell_type":"markdown","metadata":{},"source":["Y ahora, ajustamos el modelo!"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["tree_fit <- tree_workflow %>%\n","    fit(data = train_set)\n","tree_fit"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["fancyRpartPlot(tree_fit$fit$fit$fit)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["#De manera más elegante\n","tree_fit_plot <- tree_fit %>% pull_workflow_fit()\n","fancyRpartPlot(tree_fit_plot$fit)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["pred_values <- tree_fit %>% \n","    predict(test_set)\n","pred_values"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["rmse(test_set$Sale_Price, pred_values$.pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["R2 <- function(yhat,y){\n","  rss <- sum((yhat - y)^2)\n","  tss <- sum((y - mean(y))^2)\n","  rsq <- 1 - rss/tss\n","  return(rsq)\n","}\n","R2(yhat = pred_values$.pred, y = test_set$Sale_Price)"]},{"cell_type":"markdown","metadata":{},"source":["Ahora existen ciertos hiperparámetros que podemos modificar en los árboles de decisión, de modo de obtener mejores modelos (en sentido de las métricas)\n","\n","**tree_depth:** Este parámetros determina el largo máximo de las ramas que componen el árbol, desde el nodo inicial al terminal.\n","\n","**min_n:** Es el número mínimo que debe tener un nodo para poder ser dividido\n"," \n","**cost_complexity:** Parámetro de costo o complejidad del modelo (conocido como CP)."]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["tuned_model <- decision_tree(cost_complexity = tune(), tree_depth = tune()) %>%\n","    set_engine('rpart') %>%\n","    set_mode('regression')\n","\n","tuned_model"]},{"cell_type":"markdown","metadata":{},"source":["La primera forma que exploraremos para hacer tuning de hiper-parámetros es mediante grid search, esto es, generar una grilla de puntos a evaluar, y usaremos las distintas combinaciones para encontrar el mejor modelo para esa grilla."]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["tree_grid <- grid_regular(cost_complexity(),\n","                          tree_depth(),\n","                          levels = 5)\n","\n","tree_grid"]},{"cell_type":"markdown","metadata":{},"source":["Tal como lo comentamos en clase, típicamente se utiliza validación cruzada para encontrar nuestros hiper-parámetros, por lo que debemos también configurar aquello."]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["set.seed(20220901)\n","set_folds <- vfold_cv(train_set)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["tree_workflow <- workflow() %>%\n","    add_model(tuned_model) %>%\n","    add_formula(Sale_Price ~ .)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["tree_tuning <- tree_workflow %>%\n","    tune_grid(resamples = set_folds, grid = tree_grid)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["tree_tuning %>%\n","    collect_metrics()"]},{"cell_type":"markdown","metadata":{},"source":["Podemos graficar los resultados"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["tree_tuning %>%\n","  collect_metrics() %>%\n","  mutate(tree_depth = factor(tree_depth)) %>%\n","  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n","  geom_line(size = 1.5, alpha = 0.6) +\n","  geom_point(size = 2) +\n","  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n","  scale_x_log10(labels = scales::label_number()) +\n","  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)"]},{"cell_type":"markdown","metadata":{},"source":["Ahora, ¿cómo elegimos?"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["tree_tuning %>%\n","    show_best('rmse')"]},{"cell_type":"markdown","metadata":{},"source":["Y finalizamos el workflow, para tener nuestro modelos según los parámetros arrojados por el tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["best_tree <- tree_tuning %>%\n","    select_best('rmse')\n","\n","final_tree_workflow <- tree_workflow %>%\n","    finalize_workflow(best_tree)\n","\n","final_tree_workflow"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["#ahora ajustamos con los datos\n","final_tree <- final_tree_workflow %>%\n","    last_fit(traintest_split)\n","\n","final_tree %>%\n","    collect_metrics()"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["final_tree %>%\n","    extract_fit_engine() %>%\n","    rpart.plot(roundint = FALSE)"]},{"cell_type":"markdown","metadata":{},"source":["Ahora que tenemos un entendimiento de los árboles, abordaremos el concepto de Bagging\n","   \n","Este método consiste en generar replicas del dataset de entrenamiento mediante la técnica de bootstrap, de esta forma podremos entrenar nuestro modelo con distintos dataset tomando como predicciones en ellos ya sea un método de votación (en el caso de clasificación) o un promedio (en caso de regresión) entre todos.\n","\n","La formulación de este método permite claramente generarlo para cualquier modelo, pero el modelo donde más popular se ha hecho este método es utilizandolo sobre árboles de decisión, los que se conocen como Random Forest."]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["bag_model <- bag_tree() %>%\n","    set_engine('rpart') %>%\n","    set_mode('regression')\n","bag_model"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["#Modelo inicial\n","bag_wf <- workflow() %>%\n","    add_model(bag_model) %>%\n","    add_formula(Sale_Price ~ .) %>%\n","    fit(data = train_set)\n","\n","bag_wf\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["pred_values <- bag_wf %>% \n","    predict(test_set)\n","\n","rmse(test_set$Sale_Price, pred_values$.pred)\n","R2(yhat = pred_values$.pred, y = test_set$Sale_Price)"]},{"cell_type":"markdown","metadata":{},"source":["Si nos fijamos, estos resultados ya son mejores (siendo que no hemos hecho tuning de parámetros) que los de nuestro mejor árbol de decisión. Evidentemente estos modelos lo hacen un poco mejor, pero un pierde la capacidad interpretativa del modelo.\n","\n","# Random Forest \n","\n","Lo que estabamos haciendo era seleccionar un conjunto de árboles y generábamos un muestreo de filas para añadir aleatoridad a los árboles. Sin embargo ahora se le agregará un nuevo nivel: se muestrearán ciertos atributos (columnas) para cada nuevo árbol. Así, por ejemplo, el primer árbol puede tener las primeras 3 columnas con las primeras 300 filas, y el segundo árbol puede tener las siguientes columnas, con el resto de filas, generando así independencia entre los modelos.\n"," \n","Lo anterior nos permitirá eliminar el sesgo creado por el bagging, pues ya no se está entrenando siempre con todos los atributos.\n"," \n","Para ajustar el modelo, utilizaremos el package randomForest\n"," \n","Contras:\n","  - Se pierde la interpretabilidad de un árbol de decisión aislado\n"," \n","Pros:\n","  - Son mas dificiles de sobrajustar\n"," \n","La implementación del modelo sigue muy similar al de los anteriores, con la particularidad que el Random Forest, lo haremos paralelizado!!"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["require(parallel)\n","cores <- parallel::detectCores()\n","cores"]},{"cell_type":"markdown","metadata":{},"source":["Vamos a generar un modelo con tuning de parámetros de manera inmediata"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["tuned_rf_model <- rand_forest(mtry = tune(), min_n = tune(), trees = 500) %>%\n","    set_engine('ranger', num.threads = cores) %>%\n","    set_mode('regression')"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["#Ahora crearemos el workflow\n","rf_workflow <- workflow() %>%\n","    add_model(tuned_rf_model) %>%\n","    add_formula(Sale_Price ~ .)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["rf_model <- rf_workflow %>%\n","    tune_grid(set_folds,\n","              grid = 25)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["rf_model %>%\n","    collect_metrics()"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["rf_model %>%\n","    show_best('rmse')"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["best_rf <- rf_model %>%\n","    select_best('rmse')\n","\n","final_rf_workflow <- rf_workflow %>%\n","    finalize_workflow(best_rf)\n","\n","final_rf <- final_rf_workflow %>%\n","    last_fit(traintest_split)\n","\n","final_rf %>%\n","    collect_metrics()"]},{"cell_type":"markdown","metadata":{},"source":["# XGboots\n","\n","![kfcv](https://cdn.educba.com/academy/wp-content/uploads/2019/11/bagging-and-boosting.png)\n","\n","XGboost es un framework  que permite generar un modelo denominado Extreme Gradient Booting decision tree,  que se puede entender como una mejora del random forest. La parte de extreme gradiente es lo que lo hace eficiente en terminos de entrenamiento y costo computaciones, y la parte de booting refiere a la mejora de los métodos anteriores. El modelo de XGBoost funciona similar a un random forest, con la diferencia que en vez de hacerlo cada repetición independiente, va utilizando cada modelo para generado para ir mejorando los que vienen.\n","\n","Tipicamente tiene permite tener mejores resultados que sus parientes anteriores, y siguiendo el workflow de trabajo que hemos estado utilizando, veremos como ajustar un XGBoost usando tidymodels.\n","\n","Para esto, utilizaremos otro set de datos, para mostrar también un ejemplo con modelo de clasificación."]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["require(nycflights13)\n","\n","flight_data <- flights %>% \n","  mutate(\n","    arr_delay = ifelse(arr_delay >= 30, \"late\", \"on_time\"),\n","    arr_delay = factor(arr_delay),\n","    date = lubridate::as_date(time_hour)\n","  ) %>%\n","  select(dep_time, flight, origin, dest, air_time, distance, \n","         carrier, date, arr_delay) %>% \n","  na.omit() %>% \n","  mutate_if(is.character, as.factor)\n","\n","  flight_data"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["xgboost_model <- boost_tree() %>%\n","    set_engine('xgboost') %>%\n","    set_mode('classification')"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["flight_split <- initial_split(flight_data, prop = 0.8, strata = arr_delay)\n","\n","train_set <- training(flight_split)\n","test_set <- testing(flight_split)\n","\n","flight_recipe <- recipe(arr_delay ~ ., data = train_set) %>%\n","    update_role(flight, date, new_role = 'ID') %>%\n","    step_date(date, features = c('dow','month')) %>%\n","    step_dummy(all_nominal_predictors())"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["flight_wf <- workflow() %>%\n","    add_model(xgboost_model) %>%\n","    add_recipe(flight_recipe)\n","\n","flight_wf"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["flight_fit <- flight_wf %>%\n","    fit(data =train_set)"]},{"cell_type":"markdown","metadata":{},"source":["Ahora podemos analizar los resultados"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["flight_aug <- augment(flight_fit, test_set)\n","flight_aug"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["require(caret)\n","pred_values <- predict(flight_fit, test_set)\n","confusionMatrix(pred_values$.pred_class, test_set$arr_delay, positive = 'late')"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["flight_aug %>%\n","    roc_curve(truth = arr_delay, .pred_late) %>%\n","    autoplot()\n","\n","flight_aug %>%\n","    roc_auc(truth = arr_delay, .pred_late)"]},{"cell_type":"markdown","metadata":{},"source":["# Ejercicio\n","\n","Es sabido que, una entidad que presta servicios o productos (pudiera ser una empresa, un banco, una tienda, etcétera) puede mejorar la experiencia de cliente desarrollando productos personalizados en post de las preferencias y necesidades de cada uno de sus clientes.\n","\n","El set de datos potencial contiene datos sobre clientes de una institución financiera:\n","\n","- Customer ID: ID asociado al cliente\n","- Age: Edad en años del cliente\n","- Income: Ingreso anual del cliente\n","- Family: Tamaño del grupo familiar del cliente\n","- CCAvg: Cupo promedio mensual utilizado en tarjetas de crédito\n","- Education: Nivel educacional (1 si no es graduado, 2 graduado y 3 si posee estudios especializados (magister, doctorado, etcétera))\n","- Mortgage: Monto de la hipoteca (0 indica que no posee)\n","- ZIP Code: Código postal del domicilio\n","                                \n","En la última campaña a cada cliente se le ofreció un producto personalizado en base a su comportamiento financiero, preferencias, capacidad de pago y necesidades. La variable target corresponde a Personal Loan el cual indica si el cliente tomó o no tomó este producto (¿El cliente aceptó o no el producto ofrecido?), donde 0 indica que el cliente no adquirió el producto y 1 indica que sí lo adquirió.\n","\n","Es de interés analizar cuáles pudieran ser los perfiles de clientes que tienen mayor probabilidad de aceptar el producto ofrecido, de manera de, identificar a los clientes con dichas características y priorizarlos a ellos en las próximas campañas.\n"," \n","a) Cargue el set de datos. ¿Qué columnas le hacen sentido incluir en un modelo para predecir si un cliente tomará o no el producto ofrecido? Si desea eliminar alguna columna, puede hacerlo según lo visto en clases.\n","\n","b) Determine cuáles son las variables predictoras que son categorías y modifiquelas si es necesario para poder considerarlas en el modelo. \n","\n","c) Determine el set de entrenamiento y testeo en una proposición 80% y 20% respectivamente.\n","\n","d) Obtenga un árbol de decisión con el set de datos de entrenamiento. Obtenga las métricas pertinentes del modelo en el set de prueba. Muestre el árbol obtenido, ¿qué observa?  ¿cuáles podrían ser los problemas de este árbol? ¿qué alternativas pudieran probarse para abordar este problema?\n","\n","e) Plantee otro árbol de decisión pero definiendo como parámetro de control la profundidad máxima del árbol. Observe el árbol obtenido. Comente. \n","\n","f) Busque mejores valores de los hiperparámetros para este caso, y entregue sus valores. Compare con los resultados anteriores y comente"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP9HsGQ7EhWpSjdLqyVjmWr","collapsed_sections":[],"name":"Clase 3.ipynb","provenance":[]},"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"4.2.0"}},"nbformat":4,"nbformat_minor":0}
